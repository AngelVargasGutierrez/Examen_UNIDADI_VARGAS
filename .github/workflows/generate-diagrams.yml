name: Generate Infrastructure and ER Diagrams

on:
  push:
    branches: [ main ]
    paths:
      - '*.tf'
      - '.github/workflows/generate-diagrams.yml'
  workflow_dispatch:

jobs:
  generate-infrastructure-diagram:
    name: Generate Infrastructure Diagram
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install diagrams pillow

    - name: Generate Infrastructure Diagram
      run: |
        python -c "
        from diagrams import Diagram, Cluster, Edge
        from diagrams.azure.analytics import DataFactory, PowerbiEmbedded
        from diagrams.azure.database import SqlDatabases
        from diagrams.azure.storage import StorageAccounts
        from diagrams.azure.security import KeyVaults
        from diagrams.azure.general import ResourceGroups
        from diagrams.azure.devops import DevopsOrganizations
        from diagrams.programming.flowchart import StartEnd, Decision
        from diagrams.onprem.client import Users

        with Diagram('Movies Analytics Infrastructure', filename='infrastructure_diagram', show=False, direction='TB'):
            users = Users('Data Analysts')
            
            with Cluster('Azure Resource Group'):
                with Cluster('Data Storage'):
                    storage = StorageAccounts('Blob Storage\\n(CSV Files)')
                    database = SqlDatabases('SQL Database\\n(Movies Data)')
                
                with Cluster('Data Processing'):
                    adf = DataFactory('Azure Data Factory\\n(ETL Pipeline)')
                
                with Cluster('Analytics & Reporting'):
                    powerbi = PowerbiEmbedded('Power BI\\n(Reports & Dashboards)')
                
                with Cluster('Security'):
                    keyvault = KeyVaults('Key Vault\\n(Secrets & Connections)')
            
            with Cluster('CI/CD Pipeline'):
                github = DevopsOrganizations('GitHub Actions\\n(Automation)')
            
            # Data flow
            users >> Edge(label='Access Reports') >> powerbi
            storage >> Edge(label='CSV Data') >> adf
            adf >> Edge(label='Processed Data') >> database
            database >> Edge(label='Query Data') >> powerbi
            keyvault >> Edge(label='Secure Connections') >> [adf, database, powerbi]
            github >> Edge(label='Deploy & Manage') >> [storage, database, adf, powerbi, keyvault]
        
        print('Infrastructure diagram generated successfully')
        "

    - name: Generate Data Flow Diagram
      run: |
        python -c "
        from diagrams import Diagram, Cluster, Edge
        from diagrams.programming.flowchart import StartEnd, Decision, Document
        from diagrams.azure.storage import StorageAccounts
        from diagrams.azure.database import SqlDatabases
        from diagrams.azure.analytics import DataFactory, PowerbiEmbedded

        with Diagram('Data Flow Process', filename='data_flow_diagram', show=False, direction='LR'):
            start = StartEnd('CSV Upload')
            validate = Decision('Validate\\nData Quality')
            storage = StorageAccounts('Blob Storage')
            etl = DataFactory('ETL Process')
            database = SqlDatabases('SQL Database')
            powerbi = PowerbiEmbedded('Power BI Reports')
            end = StartEnd('Analytics Ready')
            
            start >> validate
            validate >> Edge(label='Valid') >> storage
            validate >> Edge(label='Invalid', style='dashed', color='red') >> start
            storage >> etl
            etl >> database
            database >> powerbi
            powerbi >> end
        
        print('Data flow diagram generated successfully')
        "

    - name: Upload Infrastructure Diagrams
      uses: actions/upload-artifact@v3
      with:
        name: infrastructure-diagrams
        path: |
          infrastructure_diagram.png
          data_flow_diagram.png

    - name: Commit diagrams to repository
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add infrastructure_diagram.png data_flow_diagram.png
        git diff --staged --quiet || git commit -m "Update infrastructure diagrams [skip ci]"
        git push

  generate-er-diagram:
    name: Generate ER Diagram and Data Dictionary
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install eralchemy2 sqlalchemy pandas

    - name: Generate ER Diagram
      run: |
        python -c "
        import pandas as pd
        from datetime import datetime

        # Create ER diagram using text representation
        er_diagram = '''
        # Movies Analytics Database - Entity Relationship Diagram

        ## Database Schema

        ```
        ┌─────────────────────────────────────────────────────────────────┐
        │                            Movies                                │
        ├─────────────────────────────────────────────────────────────────┤
        │ MovieID (PK)              │ INT                                  │
        │ Title                     │ NVARCHAR(500)                       │
        │ Genre                     │ NVARCHAR(100)                       │
        │ ReleaseYear               │ INT                                  │
        │ ReleaseDate               │ DATE                                 │
        │ Country                   │ NVARCHAR(100)                       │
        │ BudgetUSD                 │ DECIMAL(15,2)                       │
        │ US_BoxOfficeUSD           │ DECIMAL(15,2)                       │
        │ Global_BoxOfficeUSD       │ DECIMAL(15,2)                       │
        │ Opening_Day_SalesUSD      │ DECIMAL(15,2)                       │
        │ One_Week_SalesUSD         │ DECIMAL(15,2)                       │
        │ IMDbRating                │ DECIMAL(3,1)                        │
        │ RottenTomatoesScore       │ INT                                  │
        │ NumVotesIMDb              │ INT                                  │
        │ NumVotesRT                │ INT                                  │
        │ Director                  │ NVARCHAR(200)                       │
        │ LeadActor                 │ NVARCHAR(200)                       │
        │ CreatedAt                 │ DATETIME2                           │
        │ UpdatedAt                 │ DATETIME2                           │
        └─────────────────────────────────────────────────────────────────┘
        ```

        ## Indexes

        - **IX_Movies_ReleaseYear**: Index on ReleaseYear for year-based queries
        - **IX_Movies_Genre**: Index on Genre for genre-based filtering
        - **IX_Movies_Country**: Index on Country for country-based analysis
        - **IX_Movies_Director**: Index on Director for director-based queries

        ## Views

        ### vw_MoviesByYear
        Aggregated data by release year including count, averages for budget, box office, and ratings.

        ### vw_MoviesByGenre  
        Aggregated data by genre including count, averages for budget, box office, and ratings.

        ### vw_TopMoviesByRevenue
        Top 100 movies by global box office revenue with profit calculations.

        ## Relationships and Business Rules

        1. **Primary Key**: MovieID uniquely identifies each movie
        2. **Data Integrity**: Title and MovieID are required fields
        3. **Date Constraints**: ReleaseDate should be valid and ReleaseYear should match
        4. **Rating Constraints**: 
           - IMDbRating: 0.0 - 10.0
           - RottenTomatoesScore: 0 - 100
        5. **Financial Data**: All USD amounts should be non-negative
        '''

        with open('ER_Diagram.md', 'w', encoding='utf-8') as f:
            f.write(er_diagram)
        
        print('ER diagram documentation generated successfully')
        "

    - name: Generate Data Dictionary
      run: |
        python -c "
        import pandas as pd
        from datetime import datetime

        # Create comprehensive data dictionary
        data_dictionary = '''
        # Data Dictionary - Movies Analytics Database

        ## Table: Movies

        | Column Name | Data Type | Length | Nullable | Default | Description |
        |-------------|-----------|---------|----------|---------|-------------|
        | MovieID | INT | 4 | No | - | Unique identifier for each movie (Primary Key) |
        | Title | NVARCHAR | 500 | No | - | Full title of the movie |
        | Genre | NVARCHAR | 100 | Yes | NULL | Primary genre classification of the movie |
        | ReleaseYear | INT | 4 | Yes | NULL | Year the movie was released |
        | ReleaseDate | DATE | 3 | Yes | NULL | Exact release date of the movie |
        | Country | NVARCHAR | 100 | Yes | NULL | Country of origin/production |
        | BudgetUSD | DECIMAL | 15,2 | Yes | NULL | Production budget in US Dollars |
        | US_BoxOfficeUSD | DECIMAL | 15,2 | Yes | NULL | Box office revenue in the United States |
        | Global_BoxOfficeUSD | DECIMAL | 15,2 | Yes | NULL | Worldwide box office revenue |
        | Opening_Day_SalesUSD | DECIMAL | 15,2 | Yes | NULL | Revenue generated on opening day |
        | One_Week_SalesUSD | DECIMAL | 15,2 | Yes | NULL | Revenue generated in the first week |
        | IMDbRating | DECIMAL | 3,1 | Yes | NULL | Internet Movie Database rating (0.0-10.0) |
        | RottenTomatoesScore | INT | 4 | Yes | NULL | Rotten Tomatoes critic score (0-100) |
        | NumVotesIMDb | INT | 4 | Yes | NULL | Number of votes on IMDb |
        | NumVotesRT | INT | 4 | Yes | NULL | Number of reviews on Rotten Tomatoes |
        | Director | NVARCHAR | 200 | Yes | NULL | Primary director of the movie |
        | LeadActor | NVARCHAR | 200 | Yes | NULL | Lead/main actor in the movie |
        | CreatedAt | DATETIME2 | 7 | No | GETDATE() | Timestamp when record was created |
        | UpdatedAt | DATETIME2 | 7 | No | GETDATE() | Timestamp when record was last updated |

        ## Data Quality Rules

        ### Required Fields
        - **MovieID**: Must be unique and not null
        - **Title**: Must not be null or empty

        ### Data Validation Rules
        - **ReleaseYear**: Should be between 1888 (first movie) and current year + 5
        - **IMDbRating**: Valid range 0.0 to 10.0
        - **RottenTomatoesScore**: Valid range 0 to 100
        - **Financial Fields**: Should be non-negative values
        - **Date Consistency**: ReleaseDate year should match ReleaseYear when both are present

        ### Business Rules
        - **Profit Calculation**: Global_BoxOfficeUSD - BudgetUSD
        - **ROI Calculation**: (Global_BoxOfficeUSD - BudgetUSD) / BudgetUSD * 100
        - **Success Metrics**: Movies with IMDb > 7.0 or RT > 70 considered successful

        ## Indexes and Performance

        ### Primary Index
        - **PK_Movies**: Clustered index on MovieID

        ### Secondary Indexes
        - **IX_Movies_ReleaseYear**: Non-clustered index for year-based queries
        - **IX_Movies_Genre**: Non-clustered index for genre filtering
        - **IX_Movies_Country**: Non-clustered index for country analysis
        - **IX_Movies_Director**: Non-clustered index for director searches

        ## Views and Aggregations

        ### vw_MoviesByYear
        **Purpose**: Annual movie statistics and trends
        **Columns**: ReleaseYear, MovieCount, AvgBudget, AvgBoxOffice, AvgIMDbRating, AvgRTScore

        ### vw_MoviesByGenre
        **Purpose**: Genre-based analysis and comparisons
        **Columns**: Genre, MovieCount, AvgBudget, AvgBoxOffice, AvgIMDbRating, AvgRTScore

        ### vw_TopMoviesByRevenue
        **Purpose**: Highest grossing movies with profit analysis
        **Columns**: All movie details plus calculated Profit field
        **Limit**: Top 100 movies by Global_BoxOfficeUSD

        ## Data Sources and ETL

        ### Source Data
        - **File**: movies_dataset.csv
        - **Format**: Comma-separated values
        - **Encoding**: UTF-8
        - **Size**: ~1M records

        ### ETL Process
        1. **Extract**: Read CSV file from blob storage
        2. **Transform**: 
           - Data type conversions
           - Date parsing and validation
           - Null value handling
           - Text cleaning and normalization
        3. **Load**: Bulk insert into SQL Database with error handling

        ### Data Refresh
        - **Frequency**: On-demand via GitHub Actions
        - **Method**: Truncate and reload or incremental updates
        - **Validation**: Automated data quality checks post-load

        ## Usage Guidelines

        ### For Analysts
        - Use views for standard reporting queries
        - Filter by ReleaseYear for time-based analysis
        - Join with external data sources using MovieID or Title
        - Consider data completeness when analyzing financial metrics

        ### For Developers
        - Always use parameterized queries to prevent SQL injection
        - Implement proper error handling for null values
        - Use appropriate indexes for query optimization
        - Follow naming conventions for new objects

        ### For Power BI
        - Connect using SQL Server connector
        - Use views as primary data sources
        - Implement row-level security if needed
        - Cache frequently used aggregations

        ---
        *Generated on: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
        *Database Version: 1.0*
        *Last Updated: {datetime.now().strftime("%Y-%m-%d")}*
        '''

        with open('BD.md', 'w', encoding='utf-8') as f:
            f.write(data_dictionary)
        
        print('Data dictionary generated successfully')
        "

    - name: Upload ER Documentation
      uses: actions/upload-artifact@v3
      with:
        name: er-documentation
        path: |
          ER_Diagram.md
          BD.md

    - name: Commit ER documentation to repository
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add ER_Diagram.md BD.md
        git diff --staged --quiet || git commit -m "Update ER diagram and data dictionary [skip ci]"
        git push

  update-readme:
    name: Update README with Diagrams
    runs-on: ubuntu-latest
    needs: [generate-infrastructure-diagram, generate-er-diagram]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Pull latest changes
      run: git pull origin main

    - name: Update README with diagram links
      run: |
        cat > README_update.md << 'EOF'
        
        ## Architecture Diagrams

        ### Infrastructure Diagram
        ![Infrastructure Diagram](infrastructure_diagram.png)

        The infrastructure diagram shows the complete Azure architecture including:
        - **Azure SQL Database**: Stores the movies data
        - **Blob Storage**: Stores CSV files and scripts
        - **Azure Data Factory**: Handles ETL processes
        - **Power BI Embedded**: Provides analytics and reporting
        - **Key Vault**: Manages secrets and connection strings
        - **GitHub Actions**: Automates deployment and data pipeline

        ### Data Flow Diagram
        ![Data Flow Diagram](data_flow_diagram.png)

        The data flow diagram illustrates the process from CSV upload to analytics-ready data.

        ## Database Documentation

        For detailed database schema, entity relationships, and data dictionary, see:
        - [Database Documentation (BD.md)](BD.md)
        - [Entity Relationship Diagram](ER_Diagram.md)

        EOF

        # Check if README.md exists, if not create it
        if [ ! -f README.md ]; then
            echo "# Movies Analytics Project" > README.md
            echo "" >> README.md
            echo "This project provides a complete analytics solution for movie data analysis." >> README.md
        fi

        # Add the diagrams section to README if it doesn't exist
        if ! grep -q "## Architecture Diagrams" README.md; then
            cat README_update.md >> README.md
        fi

    - name: Commit updated README
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add README.md
        git diff --staged --quiet || git commit -m "Update README with architecture diagrams [skip ci]"
        git push